## Work stealing

In our ForkJoinSumCalculator we decided to stop creating more subtasks when the array of numbers to be summed contained at most 10,000 items. This is an arbitrary choice, but in most cases it's difficult to find a good heuristic, other than trying to optimize it by making several attempts with different inputs. In our test case, we started with an array of 10 million items, meaning that the ForkJoinSumCalculator will fork at least 1,000 sub-tasks. This might seem like a waste of resources because we ran it on a machine that has only four cores. In this specific case, that’s probably true because all tasks are CPU bound and are expected to take a similar amount of time. 

But  forking  a  quite  large  number  of  fine-grained  tasks  is  in  general  a  winning choice. This is because ideally you want to partition the workload of a parallelized task in such a way that each subtask takes exactly the same amount of time, keeping all the cores of your CPU equally busy. Unfortunately, especially in cases closer to real-worlds scenarios than the straightforward example we presented here, the time taken by each subtask can dramatically vary either due to the use of an inefficient partition strategy or because of unpredictable causes like slow access to the disk, or the need to coordinate the execution with external services.
 
 The fork/join framework works around this problem with a technique called work stealing. In practice, this means that the tasks are more or less evenly divided on all the threads  in  the  ForkJoinPool.  Each  of  these  threads  holds  a  doubly  linked  queue  of the tasks assigned to it, and as soon as it completes a task it pulls another one from the head  of  the  queue  and  starts  executing  it.  For  the  reasons  we  listed  previously,  one thread might complete all the tasks assigned to it much faster than the others, which means its queue will become empty while the other threads are still pretty busy. In this case,  instead  of  becoming  idle,  the  thread  randomly  chooses  a  queue  of  a  different thread and “steals” a task, taking it from the tail of the queue. This process continues until  all  the  tasks  are executed,  and  then  all  the  queues  become  empty.  That’s  why having many smaller tasks, instead of only a few bigger ones, can help in better balancing the workload among the worker threads. 
 
 More generally, this work-stealing algorithm is used to redistribute and balance the tasks among the worker threads in the pool. Figure 7.5 shows how this process occurs.When a task in the queue of a worker is divided into two subtasks, one of the two sub-tasks  is  stolen  by  another  idle  worker.  As  described  previously,  this  process  can  continue  recursively  until  the  condition  used  to  define  that  a  given  subtask  should  be executed sequentially becomes true.